{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants and path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from os import path, listdir\n",
    "import os\n",
    "\n",
    "BASE_PATH = os.getcwd()\n",
    "TRAIN_PATH = BASE_PATH + '/train_images/'\n",
    "# FULL_MODEL_PATH = BASE_PATH + '/model_weights.h5'\n",
    "FULL_MODEL_PATH = BASE_PATH + '/weights-02-0.0448.h5'\n",
    "CLASS_DEF_PATH = BASE_PATH + '/classes_def.json'\n",
    "\n",
    "MAX_CONTOURS = 30\n",
    "IMAGE_SIZE = (1600, 900)\n",
    "\n",
    "# Epsilon ratio for approxPolyDP\n",
    "# https://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html\n",
    "EPSILON_RATIO = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions for:\n",
    "- Ploting images\n",
    "- Listing all image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_data):\n",
    "    plt.imshow(img_data)\n",
    "    plt.axis('off')  # to hide the axes\n",
    "    plt.show()\n",
    "\n",
    "def get_all_files():\n",
    "    for file_name in [item for item in listdir(TRAIN_PATH) if path.isfile(TRAIN_PATH + item)]:\n",
    "        yield TRAIN_PATH + file_name\n",
    "\n",
    "file_list = list(get_all_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main processing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFile:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.file_data = cv2.imread(file_name)\n",
    "        \n",
    "        if (self.file_data.shape[0] > self.file_data.shape[1]):\n",
    "            self.file_data = cv2.resize(self.file_data, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "        else:\n",
    "            self.file_data = cv2.resize(self.file_data, (IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
    "        \n",
    "        self.file_data = cv2.cvtColor(self.file_data, cv2.COLOR_BGR2RGB)\n",
    "        self.grayscale_file = cv2.cvtColor(self.file_data, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \"\"\"\n",
    "    Thresholding the file. GaussianBlur is applied to improve thresholding result\n",
    "    For the bluring operation, we can use either\n",
    "    - GaussianBlur (faster) or\n",
    "    - BilateralFilter (better at preserving edges)\n",
    "    \n",
    "    For the thresholding operation, we can use either\n",
    "    - Adaptive threshold (slower) or \n",
    "    - OTSU threshold (global min variance)\n",
    "    \n",
    "    For the edge detection operation, we can use either\n",
    "    - Canny\n",
    "    - Laplacian\n",
    "    \n",
    "    1st trial - for general case:\n",
    "    - Bilateral Filter\n",
    "    - Otsu threshold\n",
    "    - Laplacian edge detection\n",
    "    \n",
    "    References:\n",
    "    https://docs.opencv.org/3.3.1/d7/d4d/tutorial_py_thresholding.html\n",
    "    https://docs.opencv.org/3.3.1/da/d22/tutorial_py_canny.html\n",
    "    https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.html\n",
    "    \"\"\"\n",
    "    def preprocess(self):\n",
    "        output = self.grayscale_file\n",
    "        # Grayscaling\n",
    "#         output = cv2.cvtColor(self.file_data, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Bluring\n",
    "#         output = cv2.GaussianBlur(output, (3,3), 0)\n",
    "#         output = cv2.GaussianBlur(output, (5,5), 0)\n",
    "        output = cv2.bilateralFilter(output,9,75,75)\n",
    "\n",
    "        # Thresholding\n",
    "        output = cv2.adaptiveThreshold(output,\n",
    "            255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#         thres_level, output = cv2.threshold(output,\n",
    "#             0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Edge detection\n",
    "#         output = cv2.Canny(output, 100, 200)\n",
    "        \n",
    "        # Edge detection - Laplacian\n",
    "        output = cv2.Laplacian(output, cv2.CV_64F)\n",
    "        output = np.absolute(output)\n",
    "        output = np.uint8(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \"\"\"\n",
    "    Generator function for finding card contours\n",
    "    References:\n",
    "    https://docs.opencv.org/2.4/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.html\n",
    "    \"\"\"\n",
    "    def find_cards(self, preprocessed_img):\n",
    "        dummy, contours, hierachy = cv2.findContours(preprocessed_img, \n",
    "            cv2.RETR_TREE, \n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "        \n",
    "        # sort the contours by area\n",
    "        index_sort = sorted(range(len(contours)), \n",
    "            key=lambda idx : contour_areas[idx], \n",
    "            reverse=True)\n",
    "        \n",
    "        # limit number of contours for processing\n",
    "        if MAX_CONTOURS is not None and len(index_sort) > MAX_CONTOURS:\n",
    "            index_sort = index_sort[:MAX_CONTOURS]\n",
    "            \n",
    "        for idx in index_sort:\n",
    "            peri = cv2.arcLength(contours[idx], True)\n",
    "            approx = cv2.approxPolyDP(contours[idx], EPSILON_RATIO * peri, True)\n",
    "            \n",
    "            # pick contours with no parents and 4 corners\n",
    "            # additionally, limit area of the contour (using contour_areas)\n",
    "            if len(approx) == 4 and hierachy[0][idx][3] == -1:\n",
    "#                 yield contours[idx]\n",
    "                yield approx\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function for getting information\n",
    "    and perspective transform the image\n",
    "    \"\"\"\n",
    "    def get_card_data(self, contour):\n",
    "        x, y, width, height = cv2.boundingRect(contour)\n",
    "        \n",
    "        points = contour.reshape(4, 2)\n",
    "        \n",
    "        sum_pts = np.sum(points, axis=1)\n",
    "        tl = points[np.argmin(sum_pts)]\n",
    "        br = points[np.argmax(sum_pts)]\n",
    "\n",
    "        diff_pts = np.diff(points, axis=1)\n",
    "        tr = points[np.argmin(diff_pts)]\n",
    "        bl = points[np.argmax(diff_pts)]\n",
    "        \n",
    "        # find distances between points\n",
    "        \n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        \n",
    "        maxWidth = int(max(widthA, widthB))\n",
    "        maxHeight = int(max(heightA, heightB))\n",
    "        \n",
    "        destination = np.array([\n",
    "                [0, 0],\n",
    "                [maxWidth - 1, 0],\n",
    "                [maxWidth - 1, maxHeight - 1],\n",
    "                [0, maxHeight - 1]\n",
    "            ], dtype = 'float32')\n",
    "        \n",
    "        rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "        rect[0] = tl\n",
    "        rect[1] = tr\n",
    "        rect[2] = br\n",
    "        rect[3] = bl\n",
    "        \n",
    "        perspective_transform = cv2.getPerspectiveTransform(rect, destination)\n",
    "        \n",
    "        warped_img = cv2.warpPerspective(self.grayscale_file, perspective_transform, (maxWidth, maxHeight))\n",
    "        thres_level, warped_img = cv2.threshold(warped_img,\n",
    "            0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # checks if card is horizontal and needs to be rotated\n",
    "#         print(maxWidth, maxHeight)\n",
    "        if maxWidth > 1.1 * maxHeight:\n",
    "            warped_img = self.rotate_image(warped_img, 90)\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'img': warped_img\n",
    "        }\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function for rotating the image\n",
    "    \"\"\"\n",
    "    def rotate_image(self, img_data, angle):\n",
    "        rows = img_data.shape[0]\n",
    "        cols = img_data.shape[1]\n",
    "        (cX, cY) = (cols // 2, rows // 2)\n",
    "        \n",
    "        rotation_matrix = cv2.getRotationMatrix2D((cX, cY), angle, 1)\n",
    "        \n",
    "        cos = np.abs(rotation_matrix[0, 0])\n",
    "        sin = np.abs(rotation_matrix[0, 1])\n",
    "        nW = int((rows * sin) + (cols * cos))\n",
    "        nH = int((rows * cos) + (cols * sin))\n",
    "        rotation_matrix[0, 2] += (nW / 2) - cX\n",
    "        rotation_matrix[1, 2] += (nH / 2) - cY\n",
    "        \n",
    "        return cv2.warpAffine(img_data, rotation_matrix, (nW, nH))\n",
    "    \n",
    "    def extract_cards(self, resize=None):\n",
    "        img_data = self.preprocess()\n",
    "        contours = self.find_cards(img_data)\n",
    "        \n",
    "        for contour in contours:\n",
    "            data = self.get_card_data(contour)\n",
    "            if resize is not None:\n",
    "                data['img'] = cv2.resize(data['img'], resize)\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the preprocessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_file = ImageFile(file_list[1])\n",
    "# img_file = ImageFile(TRAIN_PATH + 'DSC_1166.JPG')\n",
    "img_file = ImageFile(TRAIN_PATH + 'IMG_4010.JPG')\n",
    "# img_file = ImageFile(TRAIN_PATH + 'card21.JPG')\n",
    "img_data = img_file.preprocess()\n",
    "\n",
    "# Dimensions of the image\n",
    "print(np.shape(img_data))\n",
    "\n",
    "contours = list(img_file.find_cards(img_data))\n",
    "\n",
    "img_data = np.stack((img_data,)*3, axis=-1)\n",
    "\n",
    "if len(contours) > 0:\n",
    "    cv2.drawContours(img_data, contours, -1, (0, 0, 255), 5)\n",
    "# Plot the preprocessed file\n",
    "plot_image(img_data)\n",
    "\n",
    "# Draw the original image with contours\n",
    "img_data = img_file.file_data.copy()\n",
    "\n",
    "if len(contours) > 0:\n",
    "    cv2.drawContours(img_data, contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "plot_image(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perspective transform using the extracted contours.\n",
    "- Rotate the extracted image if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "with open(CLASS_DEF_PATH, 'r') as classes_file:\n",
    "    classes = json.load(classes_file)\n",
    "\n",
    "cards_list = list(img_file.extract_cards(resize=(224, 224)))\n",
    "\n",
    "if len(cards_list) > 0:\n",
    "    img_list = [item['img'][:, :, np.newaxis] for item in cards_list]\n",
    "    img_list = np.array(img_list, dtype='float32')\n",
    "\n",
    "    model = load_model(FULL_MODEL_PATH)\n",
    "#     model.summary()\n",
    "\n",
    "    result = model.predict(img_list, batch_size=len(img_list))\n",
    "\n",
    "    for idx, data in enumerate(cards_list):\n",
    "        image = np.stack((data['img'],)*3, axis=-1).astype('uint8')\n",
    "        plot_image(image)\n",
    "\n",
    "        predict_result = result[idx]\n",
    "        class_index = np.argmax(predict_result)\n",
    "        class_confidence = predict_result[class_index] * 100\n",
    "        print('Predicted class: %s - Confidence: %s' % (classes[class_index], class_confidence))\n",
    "        print('Rect coordinates: %s' % str((data['x'], data['y'])))\n",
    "        \n",
    "        for (class_idx, class_name) in enumerate(classes):\n",
    "            print('#%s: Class: %s, Confidence: %s' %\n",
    "                  (class_idx, class_name, predict_result[class_idx] * 100))\n",
    "else:\n",
    "    print('Found no cards within the image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
